{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "# functions needed for pr_auc_score()\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# functions needed for imbalanced_cross_validation_score()\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# sampler objects\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Classification models to compare\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.svm import SVC # SVM\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from sklearn import preprocessing \n",
    "\n",
    "#auto encoding\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.feature_bagging import FeatureBagging\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "\n",
    "from pyod.utils.utility import *\n",
    "from sklearn.utils.validation import *\n",
    "from sklearn.metrics.classification import *\n",
    "from sklearn.metrics.ranking import *\n",
    "\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc_score(clf, x, y):\n",
    "    '''\n",
    "        This function computes area under the precision-recall curve. \n",
    "    '''\n",
    "      \n",
    "    precisions, recalls,_ = precision_recall_curve(y, clf.predict_proba(x)[:,1], pos_label=1)\n",
    "    \n",
    "    return auc(recalls, precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Confusion_matrix(clf, x, y):\n",
    "    cm = metrics.confusion_matrix(y, clf.predict(x))\n",
    "    mcc = matthews_corrcoef(y, clf.predict(x))\n",
    "    \n",
    "    return (cm[0][0], cm[0][1], cm[1][0], cm[1][1], mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalanced_cross_validation_score(clf, x, y, cv, scoring, sampler):\n",
    "    \n",
    "    cv_score = 0.\n",
    "    train_score = 0.\n",
    "    test_score = 0.\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    MCC = 0\n",
    "    \n",
    "    # stratified k-fold creates folds with the same ratio of positive \n",
    "    # and negative samples as the entire dataset.\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=cv, random_state=0, shuffle=False)\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(x,y):\n",
    "        \n",
    "        xfold_train_sampled, yfold_train_sampled = sampler.fit_sample(x[train_idx],y[train_idx])\n",
    "        clf.fit(xfold_train_sampled, yfold_train_sampled)\n",
    "        \n",
    "        TN_train, FP_train, FN_train, TP_train, mcc_train = scoring(clf, xfold_train_sampled, yfold_train_sampled)\n",
    "        TN_test, FP_test, FN_test, TP_test, mcc_test  = scoring(clf, x[test_idx], y[test_idx])\n",
    "        # tn, fp, fn, tp\n",
    "        print(\"Train TP: {0} Train FP: {1} Train FN: {2} Train TN: {3}; Test TP: {4} Test FP: {5} Test FN: {6} Test TN: {7}\".format(TP_train, FP_train, FN_train, TN_train, TP_test, FP_test, FN_test, TN_test))\n",
    "        print(\"MCC train: {0} and MCC test: {1}\".format(mcc_train, mcc_test))\n",
    "        \n",
    "        TP += TP_test\n",
    "        FP += FP_test\n",
    "        FN += FN_test\n",
    "        TN += TN_test\n",
    "        MCC += mcc_test\n",
    "\n",
    "    ave_tp = TP/cv\n",
    "    ave_fp = FP/cv\n",
    "    ave_fn = FN/cv\n",
    "    ave_tn = TN/cv\n",
    "    ave_mcc = MCC/cv\n",
    "    \n",
    "    sensitivity = ave_tp/(ave_tp + ave_fn)\n",
    "    specificity = ave_tn/(ave_fp + ave_tn)\n",
    "    \n",
    "    g_mean = math.sqrt(sensitivity * specificity)\n",
    "    \n",
    "    values = [sensitivity, specificity, g_mean, ave_mcc]\n",
    "    \n",
    "        \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_print(clf_name, y, y_pred):\n",
    "    \"\"\"\n",
    "    Utility function for evaluating and printing the results for examples\n",
    "    Internal use only\n",
    "\n",
    "    :param clf_name: The name of the detector\n",
    "    :type clf_name: str\n",
    "\n",
    "    :param y: The ground truth\n",
    "    :type y: list or array of shape (n_samples,)\n",
    "\n",
    "    :param y_pred: The predicted outlier scores\n",
    "    :type y: list or array of shape (n_samples,)\n",
    "    \"\"\"\n",
    "\n",
    "    # turn raw prediction decision scores into binary labels\n",
    "    y_pred = get_label_n(y, y_pred)\n",
    "\n",
    "    # enforce formats of y and labels_\n",
    "    y = column_or_1d(y)\n",
    "    y_pred = column_or_1d(y_pred)\n",
    "\n",
    "    Y_true = y.tolist()\n",
    "    N = Y_true.count(0)\n",
    "    P = Y_true.count(1)\n",
    "\n",
    "    roc = np.round(roc_auc_score(y, y_pred), decimals=4)\n",
    "    prn = np.round(precision_score(y, y_pred), decimals=4)\n",
    "    rec = np.round(recall_score(y, y_pred), decimals=4)\n",
    "    f = np.round((2 * prn * rec / (prn + rec)), decimals=4)\n",
    "    fp = np.round((P * rec * (1 - prn)) / (prn * N), decimals=4)\n",
    "    \n",
    "    # print('Algorithm:', clf_name)\n",
    "    # print('Accuracy={}, precision={}, recall={}, f_score={}, false_positive={}'.format(roc,prn,rec,f,fp))\n",
    "    # return True\n",
    "    return roc, prn, rec, f, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "class myAD_Thread(Thread):\n",
    "    # the testing data and labels are from above\n",
    "    def __init__(self, option, data=x, label=y):\n",
    "        Thread.__init__(self)\n",
    "        self.option = option\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        # self.a = a\n",
    "        # self.b = b\n",
    "        self.clfs = {\n",
    "            'PCA': PCA(),\n",
    "            'OCSVM': OCSVM(),\n",
    "            'KNN': KNN(),\n",
    "            'ABOD': ABOD(),\n",
    "            \"FB\": FeatureBagging(),\n",
    "            'AE': AutoEncoder()\n",
    "        }\n",
    "\n",
    "    def AD_algo(self):\n",
    "        print('testing with %s ...' % (self.option))\n",
    "        # fit PCA detector\n",
    "        # clf_name = 'PCA'\n",
    "        clf_name = self.option\n",
    "        clf = self.clfs[clf_name]\n",
    "        clf.fit(self.data)\n",
    "\n",
    "        # get the prediction labels and outlier scores\n",
    "        y_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "        y_scores = clf.decision_scores_  # raw outlier scores\n",
    "\n",
    "        cm = metrics.confusion_matrix(y, y_pred)\n",
    "        mcc = matthews_corrcoef(y, y_pred)\n",
    "\n",
    "\n",
    "        # evaluate and print the results\n",
    "        roc, prn, rec, f1, fp = evaluation_print(clf_name, self.label, y_scores)\n",
    "        print('%s: Results for Algorithm %s are:' % (self.getName(), clf_name))\n",
    "        print('Accuracy={}, precision={}, recall={}, f_score={}, false_positive={}, MCC={}, FP={}, FN={}'.format(roc, prn, rec, f1, fp, mcc, cm[0,1], cm[1,0]))\n",
    "        # c = self.a + self.b\n",
    "        # print('result for %s is:' % (self.getName()))\n",
    "        # print(c)\n",
    "        f = open(\"./results/AD_pyod.txt\", \"a\")\n",
    "        f.write('--------------------------------------------\\n')\n",
    "        f.write('%s: Results for Algorithm %s are:\\n' % (self.getName(), clf_name))\n",
    "        f.write('Accuracy={}, precision={}, recall={}, f_score={}, false_positive={}\\n'.format(roc, prn, rec, f1, fp))\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_o = pd.read_csv('financial_data.csv')\n",
    "y_train_o = pd.read_csv('revealed_businesses.csv')\n",
    "\n",
    "x_test_o = pd.read_csv(\"testing_data.csv\")\n",
    "\n",
    "x_train_o.replace('?', np.nan, inplace=True)\n",
    "x_train_o = x_train_o.astype('float64')\n",
    "\n",
    "\n",
    "x_test_o.replace('?', np.nan, inplace=True)\n",
    "x_test_o = x_test_o.astype('float64')\n",
    "\n",
    "data_all = x_train_o.merge(y_train_o, on='Var1', how = 'left')\n",
    "\n",
    "data_nolabel = data_all[data_all.Var66.isnull()]\n",
    "data_label = data_all[data_all.Var66.notnull()]\n",
    "\n",
    "data_nolabel_v = data_nolabel.drop(columns=['Var1', 'Var66'])\n",
    "data_nolabel_id = data_nolabel['Var1']\n",
    "\n",
    "data_label_v = data_label.drop(columns=['Var1', 'Var66'])\n",
    "data_label_id = data_label['Var1']\n",
    "\n",
    "data_nolabel_v_f = data_nolabel_v.fillna(data_nolabel_v.mean())\n",
    "data_label_v_f = data_label_v.fillna(data_label_v.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_label_v_f.values\n",
    "y = data_label['Var66'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocessing.Normalizer().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Starting...\n",
      "testing with PCA ...\n",
      "Thread 1: Results for Algorithm PCA are:\n",
      "Accuracy=0.5002, precision=0.0353, recall=0.0353, f_score=0.0353, false_positive=0.0348, MCC=0.03351388104602396, FP=462, FN=144\n",
      "testing with OCSVM ...\n",
      "Thread 2: Results for Algorithm OCSVM are:\n",
      "Accuracy=0.5338, precision=0.1, recall=0.1, f_score=0.1, false_positive=0.0325, MCC=0.07076594866883137, FP=452, FN=134\n",
      "testing with KNN ...\n",
      "Thread 3: Results for Algorithm KNN are:\n",
      "Accuracy=0.5063, precision=0.0471, recall=0.0471, f_score=0.0471, false_positive=0.0344, MCC=0.03351388104602396, FP=462, FN=144\n",
      "testing with ABOD ...\n",
      "Thread 4: Results for Algorithm ABOD are:\n",
      "Accuracy=0.4972, precision=0.0294, recall=0.0294, f_score=0.0294, false_positive=0.035, MCC=0.029788674283743218, FP=463, FN=145\n",
      "testing with FB ...\n",
      "Thread 5: Results for Algorithm FB are:\n",
      "Accuracy=0.5246, precision=0.0824, recall=0.0824, f_score=0.0824, false_positive=0.0331, MCC=0.09684239600479658, FP=445, FN=127\n",
      "testing with AE ...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                4160      \n",
      "=================================================================\n",
      "Total params: 21,888\n",
      "Trainable params: 21,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4391 samples, validate on 488 samples\n",
      "Epoch 1/100\n",
      "4391/4391 [==============================] - 1s 173us/step - loss: 107.9394 - val_loss: 49.6678\n",
      "Epoch 2/100\n",
      "4391/4391 [==============================] - 0s 49us/step - loss: 39.6440 - val_loss: 27.1790\n",
      "Epoch 3/100\n",
      "4391/4391 [==============================] - 0s 47us/step - loss: 23.9551 - val_loss: 18.3977\n",
      "Epoch 4/100\n",
      "4391/4391 [==============================] - 0s 47us/step - loss: 16.6796 - val_loss: 13.2793\n",
      "Epoch 5/100\n",
      "4391/4391 [==============================] - 0s 48us/step - loss: 12.4470 - val_loss: 10.6943\n",
      "Epoch 6/100\n",
      "4391/4391 [==============================] - 0s 49us/step - loss: 9.7686 - val_loss: 9.1462\n",
      "Epoch 7/100\n",
      "4391/4391 [==============================] - 0s 49us/step - loss: 7.9396 - val_loss: 7.9831\n",
      "Epoch 8/100\n",
      "4391/4391 [==============================] - 0s 50us/step - loss: 6.6084 - val_loss: 7.2798\n",
      "Epoch 9/100\n",
      "4391/4391 [==============================] - 0s 49us/step - loss: 5.6502 - val_loss: 6.6300\n",
      "Epoch 10/100\n",
      "4391/4391 [==============================] - 0s 48us/step - loss: 4.9231 - val_loss: 6.0647\n",
      "Epoch 11/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 4.3788 - val_loss: 5.5306\n",
      "Epoch 12/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 3.9479 - val_loss: 5.1394\n",
      "Epoch 13/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 3.6371 - val_loss: 4.7963\n",
      "Epoch 14/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 3.3513 - val_loss: 4.4342\n",
      "Epoch 15/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 3.0753 - val_loss: 4.1789\n",
      "Epoch 16/100\n",
      "4391/4391 [==============================] - 0s 44us/step - loss: 2.8790 - val_loss: 3.9126\n",
      "Epoch 17/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 2.7115 - val_loss: 3.7305\n",
      "Epoch 18/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 2.5823 - val_loss: 3.5439\n",
      "Epoch 19/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 2.4355 - val_loss: 3.3863\n",
      "Epoch 20/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 2.3422 - val_loss: 3.2538\n",
      "Epoch 21/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 2.2402 - val_loss: 3.1153\n",
      "Epoch 22/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 2.1567 - val_loss: 3.0029\n",
      "Epoch 23/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 2.0724 - val_loss: 2.9192\n",
      "Epoch 24/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 2.0126 - val_loss: 2.8307\n",
      "Epoch 25/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.9536 - val_loss: 2.7539\n",
      "Epoch 26/100\n",
      "4391/4391 [==============================] - 0s 47us/step - loss: 1.9047 - val_loss: 2.6968\n",
      "Epoch 27/100\n",
      "4391/4391 [==============================] - 0s 47us/step - loss: 1.8518 - val_loss: 2.6349\n",
      "Epoch 28/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.8039 - val_loss: 2.5775\n",
      "Epoch 29/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.7647 - val_loss: 2.5352\n",
      "Epoch 30/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.7266 - val_loss: 2.4764\n",
      "Epoch 31/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.6949 - val_loss: 2.4441\n",
      "Epoch 32/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.6619 - val_loss: 2.3799\n",
      "Epoch 33/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.6306 - val_loss: 2.3423\n",
      "Epoch 34/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.5992 - val_loss: 2.3149\n",
      "Epoch 35/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.5744 - val_loss: 2.2804\n",
      "Epoch 36/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.5466 - val_loss: 2.2548\n",
      "Epoch 37/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.5244 - val_loss: 2.2216\n",
      "Epoch 38/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.4982 - val_loss: 2.2004\n",
      "Epoch 39/100\n",
      "4391/4391 [==============================] - 0s 47us/step - loss: 1.4782 - val_loss: 2.1792\n",
      "Epoch 40/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.4547 - val_loss: 2.1456\n",
      "Epoch 41/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.4345 - val_loss: 2.1304\n",
      "Epoch 42/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.4162 - val_loss: 2.1104\n",
      "Epoch 43/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.3972 - val_loss: 2.0918\n",
      "Epoch 44/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.3787 - val_loss: 2.0701\n",
      "Epoch 45/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.3605 - val_loss: 2.0587\n",
      "Epoch 46/100\n",
      "4391/4391 [==============================] - 0s 48us/step - loss: 1.3440 - val_loss: 2.0436\n",
      "Epoch 47/100\n",
      "4391/4391 [==============================] - 0s 49us/step - loss: 1.3283 - val_loss: 2.0217\n",
      "Epoch 48/100\n",
      "4391/4391 [==============================] - 0s 50us/step - loss: 1.3117 - val_loss: 2.0034\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4391/4391 [==============================] - 0s 47us/step - loss: 1.2982 - val_loss: 1.9919\n",
      "Epoch 50/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.2861 - val_loss: 1.9782\n",
      "Epoch 51/100\n",
      "4391/4391 [==============================] - 0s 48us/step - loss: 1.2713 - val_loss: 1.9686\n",
      "Epoch 52/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.2579 - val_loss: 1.9529\n",
      "Epoch 53/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.2459 - val_loss: 1.9390\n",
      "Epoch 54/100\n",
      "4391/4391 [==============================] - 0s 47us/step - loss: 1.2316 - val_loss: 1.9304\n",
      "Epoch 55/100\n",
      "4391/4391 [==============================] - 0s 48us/step - loss: 1.2219 - val_loss: 1.9230\n",
      "Epoch 56/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.2119 - val_loss: 1.9098\n",
      "Epoch 57/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.2011 - val_loss: 1.9021\n",
      "Epoch 58/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.1905 - val_loss: 1.8922\n",
      "Epoch 59/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.1809 - val_loss: 1.8850\n",
      "Epoch 60/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.1709 - val_loss: 1.8781\n",
      "Epoch 61/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.1624 - val_loss: 1.8716\n",
      "Epoch 62/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.1532 - val_loss: 1.8642\n",
      "Epoch 63/100\n",
      "4391/4391 [==============================] - 0s 48us/step - loss: 1.1462 - val_loss: 1.8564\n",
      "Epoch 64/100\n",
      "4391/4391 [==============================] - 0s 50us/step - loss: 1.1375 - val_loss: 1.8542\n",
      "Epoch 65/100\n",
      "4391/4391 [==============================] - 0s 49us/step - loss: 1.1297 - val_loss: 1.8361\n",
      "Epoch 66/100\n",
      "4391/4391 [==============================] - 0s 47us/step - loss: 1.1236 - val_loss: 1.8246\n",
      "Epoch 67/100\n",
      "4391/4391 [==============================] - 0s 47us/step - loss: 1.1154 - val_loss: 1.8190\n",
      "Epoch 68/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.1080 - val_loss: 1.8128\n",
      "Epoch 69/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.1019 - val_loss: 1.8050\n",
      "Epoch 70/100\n",
      "4391/4391 [==============================] - 0s 47us/step - loss: 1.0956 - val_loss: 1.7998\n",
      "Epoch 71/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0897 - val_loss: 1.7948\n",
      "Epoch 72/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.0842 - val_loss: 1.7899\n",
      "Epoch 73/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0787 - val_loss: 1.7852\n",
      "Epoch 74/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0738 - val_loss: 1.7794\n",
      "Epoch 75/100\n",
      "4391/4391 [==============================] - 0s 44us/step - loss: 1.0694 - val_loss: 1.7747\n",
      "Epoch 76/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0645 - val_loss: 1.7710\n",
      "Epoch 77/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.0601 - val_loss: 1.7673\n",
      "Epoch 78/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0561 - val_loss: 1.7711\n",
      "Epoch 79/100\n",
      "4391/4391 [==============================] - 0s 47us/step - loss: 1.0521 - val_loss: 1.7678\n",
      "Epoch 80/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0479 - val_loss: 1.7548\n",
      "Epoch 81/100\n",
      "4391/4391 [==============================] - 0s 47us/step - loss: 1.0445 - val_loss: 1.7516\n",
      "Epoch 82/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0414 - val_loss: 1.7486\n",
      "Epoch 83/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0380 - val_loss: 1.7456\n",
      "Epoch 84/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.0348 - val_loss: 1.7428\n",
      "Epoch 85/100\n",
      "4391/4391 [==============================] - 0s 47us/step - loss: 1.0320 - val_loss: 1.7401\n",
      "Epoch 86/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0291 - val_loss: 1.7376\n",
      "Epoch 87/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0265 - val_loss: 1.7353\n",
      "Epoch 88/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.0243 - val_loss: 1.7330\n",
      "Epoch 89/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0219 - val_loss: 1.7309\n",
      "Epoch 90/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.0198 - val_loss: 1.7289\n",
      "Epoch 91/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.0177 - val_loss: 1.7270\n",
      "Epoch 92/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.0158 - val_loss: 1.7251\n",
      "Epoch 93/100\n",
      "4391/4391 [==============================] - 0s 44us/step - loss: 1.0140 - val_loss: 1.7235\n",
      "Epoch 94/100\n",
      "4391/4391 [==============================] - 0s 44us/step - loss: 1.0123 - val_loss: 1.7219\n",
      "Epoch 95/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0108 - val_loss: 1.7204\n",
      "Epoch 96/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0093 - val_loss: 1.7190\n",
      "Epoch 97/100\n",
      "4391/4391 [==============================] - 0s 46us/step - loss: 1.0079 - val_loss: 1.7177\n",
      "Epoch 98/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.0067 - val_loss: 1.7165\n",
      "Epoch 99/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.0054 - val_loss: 1.7154\n",
      "Epoch 100/100\n",
      "4391/4391 [==============================] - 0s 45us/step - loss: 1.0043 - val_loss: 1.7144\n",
      "Thread 6: Results for Algorithm AE are:\n",
      "Accuracy=0.5002, precision=0.0353, recall=0.0353, f_score=0.0353, false_positive=0.0348, MCC=0.03351388104602396, FP=462, FN=144\n",
      "Main Terminating...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # nameDict = ['PCA', 'OCSVM', 'KNN', 'ABOD', 'FB', 'AE']\n",
    "    # threads = []\n",
    "    # nameDict = ['PCA', 'KNN']\n",
    "    # for idx, algo_name in enumerate(nameDict, 1):\n",
    "    #     t = threading.Thread(target=myAD_pyod, args=(algo_name,))\n",
    "    #     threads.append(t)\n",
    "    #     t.start()\n",
    "    print('Main Starting...')\n",
    "    \n",
    "    data_id = 'test'\n",
    "\n",
    "    f = open(\"./results/AD_pyod.txt\", \"a\")\n",
    "    f.write('--------------------------------------------\\n')\n",
    "    f.write('--------------------------------------------\\n')\n",
    "    f.write('Pyod Results for Data-set: %s\\n' % data_id)\n",
    "    f.write('--------------------------------------------\\n')\n",
    "    f.close()\n",
    "\n",
    "    myThreadOb1 = myAD_Thread(\"PCA\")\n",
    "    myThreadOb1.setName('Thread 1')\n",
    "\n",
    "    myThreadOb2 = myAD_Thread(\"OCSVM\")\n",
    "    myThreadOb2.setName('Thread 2')\n",
    "\n",
    "    myThreadOb3 = myAD_Thread(\"KNN\")\n",
    "    myThreadOb3.setName('Thread 3')\n",
    "\n",
    "    myThreadOb4 = myAD_Thread(\"ABOD\")\n",
    "    myThreadOb4.setName('Thread 4')\n",
    "\n",
    "    myThreadOb5 = myAD_Thread(\"FB\")\n",
    "    myThreadOb5.setName('Thread 5')\n",
    "\n",
    "    myThreadOb6 = myAD_Thread(\"AE\")\n",
    "    myThreadOb6.setName('Thread 6')\n",
    "\n",
    "    # Start running the threads!\n",
    "    myThreadOb1.AD_algo()\n",
    "    myThreadOb2.AD_algo()\n",
    "    myThreadOb3.AD_algo()\n",
    "    myThreadOb4.AD_algo()\n",
    "    myThreadOb5.AD_algo()\n",
    "    myThreadOb6.AD_algo()\n",
    "\n",
    "    print('Main Terminating...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
