{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# functions needed for pr_auc_score()\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# functions needed for imbalanced_cross_validation_score()\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# sampler objects\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Classification models to compare\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.svm import SVC # SVM\n",
    "\n",
    "from sklearn import preprocessing \n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc_score(clf, x, y):\n",
    "    '''\n",
    "        This function computes area under the precision-recall curve. \n",
    "    '''\n",
    "      \n",
    "    precisions, recalls,_ = precision_recall_curve(y, clf.predict_proba(x)[:,1], pos_label=1)\n",
    "    \n",
    "    return auc(recalls, precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FP_FN_score(clf, x, y):\n",
    "    cm = metrics.confusion_matrix(y, clf.predict(x))\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "    return FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalanced_cross_validation_score(clf, x, y, cv, scoring, sampler):\n",
    "    '''\n",
    "        This function computes the cross-validation score of a given \n",
    "        classifier using a choice of sampling function to mitigate \n",
    "        the class imbalance, and stratified k-fold sampling.\n",
    "        \n",
    "        The first five arguments are the same as \n",
    "        sklearn.model_selection.cross_val_score.\n",
    "        \n",
    "        - clf.predict_proba(x) returns class label probabilities\n",
    "        - clf.fit(x,y) trains the model\n",
    "        \n",
    "        - x = data\n",
    "        \n",
    "        - y = labels\n",
    "        \n",
    "        - cv = the number of folds in the cross validation\n",
    "        \n",
    "        - scoring(classifier, x, y) returns a float\n",
    "        \n",
    "        The last argument is a choice of random sampler: an object \n",
    "        similar to the sampler objects available from the python \n",
    "        package imbalanced-learn. In particular, this \n",
    "        object needs to have the method:\n",
    "        \n",
    "        sampler.fit_sample(x,y)\n",
    "        \n",
    "        See http://contrib.scikit-learn.org/imbalanced-learn/\n",
    "        for more details and examples of other sampling objects \n",
    "        available.  \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    cv_score = 0.\n",
    "    train_score = 0.\n",
    "    test_score = 0.\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    # stratified k-fold creates folds with the same ratio of positive \n",
    "    # and negative samples as the entire dataset.\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=cv, random_state=0, shuffle=False)\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(x,y):\n",
    "        \n",
    "        xfold_train_sampled, yfold_train_sampled = sampler.fit_sample(x[train_idx],y[train_idx])\n",
    "        clf.fit(xfold_train_sampled, yfold_train_sampled)\n",
    "        \n",
    "        FP_train, FN_train = scoring(clf, xfold_train_sampled, yfold_train_sampled)\n",
    "        FP_test, FN_test  = scoring(clf, x[test_idx], y[test_idx])\n",
    "        \n",
    "        print(\"Train FP: {0} Train FN: {1}; Test FP: {2} Test FN: {3}\".format(FP_train,FN_train, FP_test, FN_test))\n",
    "\n",
    "        FP += FP_test\n",
    "        FN += FN_test\n",
    "        \n",
    "    return FP/cv, FN/cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_o = pd.read_csv('financial_data.csv')\n",
    "y_train_o = pd.read_csv('revealed_businesses.csv')\n",
    "\n",
    "x_test_o = pd.read_csv(\"testing_data.csv\")\n",
    "\n",
    "x_train_o.replace('?', np.nan, inplace=True)\n",
    "x_train_o = x_train_o.astype('float64')\n",
    "\n",
    "\n",
    "x_test_o.replace('?', np.nan, inplace=True)\n",
    "x_test_o = x_test_o.astype('float64')\n",
    "\n",
    "data_all = x_train_o.merge(y_train_o, on='Var1', how = 'left')\n",
    "\n",
    "data_nolabel = data_all[data_all.Var66.isnull()]\n",
    "data_label = data_all[data_all.Var66.notnull()]\n",
    "\n",
    "data_nolabel_v = data_nolabel.drop(columns=['Var1', 'Var66'])\n",
    "data_nolabel_id = data_nolabel['Var1']\n",
    "\n",
    "data_label_v = data_label.drop(columns=['Var1', 'Var66'])\n",
    "data_label_id = data_label['Var1']\n",
    "\n",
    "data_nolabel_v_f = data_nolabel_v.fillna(data_nolabel_v.mean())\n",
    "data_label_v_f = data_label_v.fillna(data_label_v.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_label_v_f.values\n",
    "y = data_label['Var66'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocessing.StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: gnb\n",
      "Random over-sampling\n",
      "Train FP: 3457 Train FN: 46; Test FP: 859 Test FN: 2\n",
      "Train FP: 3357 Train FN: 88; Test FP: 843 Test FN: 4\n",
      "Train FP: 3362 Train FN: 86; Test FP: 865 Test FN: 4\n",
      "Train FP: 3347 Train FN: 93; Test FP: 835 Test FN: 3\n",
      "Train FP: 3441 Train FN: 34; Test FP: 860 Test FN: 5\n",
      "average FP: 852.40 average FN: 3.60 \n",
      "SMOTE over-sampling\n",
      "Train FP: 3331 Train FN: 95; Test FP: 824 Test FN: 2\n",
      "Train FP: 3274 Train FN: 81; Test FP: 825 Test FN: 6\n",
      "Train FP: 3228 Train FN: 107; Test FP: 827 Test FN: 6\n",
      "Train FP: 3227 Train FN: 93; Test FP: 798 Test FN: 3\n",
      "Train FP: 3311 Train FN: 80; Test FP: 822 Test FN: 5\n",
      "average FP: 819.20 average FN: 4.40 \n",
      "ADASYN over-sampling\n",
      "Train FP: 3317 Train FN: 95; Test FP: 820 Test FN: 2\n",
      "Train FP: 3282 Train FN: 98; Test FP: 827 Test FN: 5\n",
      "Train FP: 3222 Train FN: 134; Test FP: 827 Test FN: 6\n",
      "Train FP: 3238 Train FN: 102; Test FP: 801 Test FN: 3\n",
      "Train FP: 3307 Train FN: 70; Test FP: 822 Test FN: 5\n",
      "average FP: 819.40 average FN: 4.20 \n",
      "Random under-sampling\n",
      "Train FP: 10 Train FN: 96; Test FP: 128 Test FN: 27\n",
      "Train FP: 46 Train FN: 30; Test FP: 334 Test FN: 9\n",
      "Train FP: 10 Train FN: 104; Test FP: 100 Test FN: 30\n",
      "Train FP: 109 Train FN: 3; Test FP: 798 Test FN: 3\n",
      "Train FP: 8 Train FN: 102; Test FP: 122 Test FN: 28\n",
      "average FP: 296.40 average FN: 19.40 \n",
      "Classifier: svm\n",
      "Random over-sampling\n",
      "Train FP: 1195 Train FN: 566; Test FP: 290 Test FN: 11\n",
      "Train FP: 1093 Train FN: 662; Test FP: 303 Test FN: 14\n",
      "Train FP: 1136 Train FN: 805; Test FP: 267 Test FN: 13\n",
      "Train FP: 1074 Train FN: 785; Test FP: 293 Test FN: 13\n",
      "Train FP: 1051 Train FN: 849; Test FP: 256 Test FN: 15\n",
      "average FP: 281.80 average FN: 13.20 \n",
      "SMOTE over-sampling\n",
      "Train FP: 1391 Train FN: 402; Test FP: 327 Test FN: 11\n",
      "Train FP: 1288 Train FN: 476; Test FP: 325 Test FN: 13\n",
      "Train FP: 1274 Train FN: 495; Test FP: 306 Test FN: 11\n",
      "Train FP: 1271 Train FN: 480; Test FP: 349 Test FN: 10\n",
      "Train FP: 1200 Train FN: 555; Test FP: 305 Test FN: 14\n",
      "average FP: 322.40 average FN: 11.80 \n",
      "ADASYN over-sampling\n",
      "Train FP: 1389 Train FN: 403; Test FP: 333 Test FN: 11\n",
      "Train FP: 1318 Train FN: 442; Test FP: 331 Test FN: 11\n",
      "Train FP: 1358 Train FN: 431; Test FP: 328 Test FN: 10\n",
      "Train FP: 1245 Train FN: 541; Test FP: 342 Test FN: 10\n",
      "Train FP: 1303 Train FN: 520; Test FP: 331 Test FN: 15\n",
      "average FP: 333.00 average FN: 11.40 \n",
      "Random under-sampling\n",
      "Train FP: 44 Train FN: 28; Test FP: 353 Test FN: 11\n",
      "Train FP: 34 Train FN: 31; Test FP: 354 Test FN: 12\n",
      "Train FP: 46 Train FN: 34; Test FP: 292 Test FN: 14\n",
      "Train FP: 30 Train FN: 45; Test FP: 332 Test FN: 11\n",
      "Train FP: 37 Train FN: 37; Test FP: 335 Test FN: 9\n",
      "average FP: 333.20 average FN: 11.40 \n",
      "Classifier: lr\n",
      "Random over-sampling\n",
      "Train FP: 1191 Train FN: 811; Test FP: 285 Test FN: 11\n",
      "Train FP: 1161 Train FN: 871; Test FP: 311 Test FN: 12\n",
      "Train FP: 1155 Train FN: 874; Test FP: 288 Test FN: 14\n",
      "Train FP: 1208 Train FN: 970; Test FP: 317 Test FN: 9\n",
      "Train FP: 1190 Train FN: 920; Test FP: 300 Test FN: 7\n",
      "average FP: 300.20 average FN: 10.60 \n",
      "SMOTE over-sampling\n",
      "Train FP: 1283 Train FN: 546; Test FP: 308 Test FN: 9\n",
      "Train FP: 1198 Train FN: 561; Test FP: 312 Test FN: 11\n",
      "Train FP: 1229 Train FN: 614; Test FP: 311 Test FN: 15\n",
      "Train FP: 1241 Train FN: 682; Test FP: 330 Test FN: 8\n",
      "Train FP: 1275 Train FN: 603; Test FP: 317 Test FN: 7\n",
      "average FP: 315.60 average FN: 10.00 \n",
      "ADASYN over-sampling\n",
      "Train FP: 1286 Train FN: 598; Test FP: 306 Test FN: 10\n",
      "Train FP: 1218 Train FN: 594; Test FP: 325 Test FN: 11\n",
      "Train FP: 1259 Train FN: 631; Test FP: 310 Test FN: 13\n",
      "Train FP: 1239 Train FN: 739; Test FP: 330 Test FN: 8\n",
      "Train FP: 1328 Train FN: 626; Test FP: 326 Test FN: 8\n",
      "average FP: 319.40 average FN: 10.00 \n",
      "Random under-sampling\n",
      "Train FP: 36 Train FN: 31; Test FP: 314 Test FN: 13\n",
      "Train FP: 38 Train FN: 36; Test FP: 355 Test FN: 11\n",
      "Train FP: 41 Train FN: 37; Test FP: 270 Test FN: 14\n",
      "Train FP: 31 Train FN: 32; Test FP: 322 Test FN: 12\n",
      "Train FP: 36 Train FN: 31; Test FP: 293 Test FN: 14\n",
      "average FP: 310.80 average FN: 12.80 \n",
      "Classifier: rfc\n",
      "Random over-sampling\n",
      "Train FP: 0 Train FN: 0; Test FP: 3 Test FN: 25\n",
      "Train FP: 0 Train FN: 0; Test FP: 2 Test FN: 28\n",
      "Train FP: 0 Train FN: 0; Test FP: 1 Test FN: 23\n",
      "Train FP: 1 Train FN: 0; Test FP: 0 Test FN: 26\n",
      "Train FP: 1 Train FN: 0; Test FP: 0 Test FN: 30\n",
      "average FP: 1.20 average FN: 26.40 \n",
      "SMOTE over-sampling\n",
      "Train FP: 0 Train FN: 1; Test FP: 13 Test FN: 21\n",
      "Train FP: 0 Train FN: 1; Test FP: 12 Test FN: 20\n",
      "Train FP: 1 Train FN: 1; Test FP: 6 Test FN: 18\n",
      "Train FP: 0 Train FN: 2; Test FP: 8 Test FN: 25\n",
      "Train FP: 1 Train FN: 2; Test FP: 12 Test FN: 25\n",
      "average FP: 10.20 average FN: 21.80 \n",
      "ADASYN over-sampling\n",
      "Train FP: 1 Train FN: 2; Test FP: 17 Test FN: 24\n",
      "Train FP: 1 Train FN: 0; Test FP: 16 Test FN: 20\n",
      "Train FP: 3 Train FN: 4; Test FP: 9 Test FN: 16\n",
      "Train FP: 2 Train FN: 1; Test FP: 12 Test FN: 19\n",
      "Train FP: 0 Train FN: 0; Test FP: 8 Test FN: 21\n",
      "average FP: 12.40 average FN: 20.00 \n",
      "Random under-sampling\n",
      "Train FP: 1 Train FN: 3; Test FP: 207 Test FN: 10\n",
      "Train FP: 1 Train FN: 3; Test FP: 250 Test FN: 7\n",
      "Train FP: 1 Train FN: 2; Test FP: 287 Test FN: 21\n",
      "Train FP: 0 Train FN: 1; Test FP: 215 Test FN: 9\n",
      "Train FP: 0 Train FN: 3; Test FP: 204 Test FN: 7\n",
      "average FP: 232.60 average FN: 10.80 \n",
      "Classifier: et\n",
      "Random over-sampling\n",
      "Train FP: 0 Train FN: 0; Test FP: 1 Test FN: 33\n",
      "Train FP: 0 Train FN: 0; Test FP: 4 Test FN: 31\n",
      "Train FP: 0 Train FN: 0; Test FP: 2 Test FN: 26\n",
      "Train FP: 0 Train FN: 0; Test FP: 0 Test FN: 33\n",
      "Train FP: 0 Train FN: 0; Test FP: 0 Test FN: 32\n",
      "average FP: 1.40 average FN: 31.00 \n",
      "SMOTE over-sampling\n",
      "Train FP: 0 Train FN: 0; Test FP: 9 Test FN: 25\n",
      "Train FP: 0 Train FN: 0; Test FP: 19 Test FN: 28\n",
      "Train FP: 0 Train FN: 0; Test FP: 9 Test FN: 21\n",
      "Train FP: 0 Train FN: 0; Test FP: 6 Test FN: 26\n",
      "Train FP: 0 Train FN: 0; Test FP: 9 Test FN: 27\n",
      "average FP: 10.40 average FN: 25.40 \n",
      "ADASYN over-sampling\n",
      "Train FP: 0 Train FN: 0; Test FP: 15 Test FN: 24\n",
      "Train FP: 0 Train FN: 0; Test FP: 17 Test FN: 27\n",
      "Train FP: 0 Train FN: 0; Test FP: 9 Test FN: 21\n",
      "Train FP: 0 Train FN: 0; Test FP: 14 Test FN: 26\n",
      "Train FP: 0 Train FN: 0; Test FP: 3 Test FN: 24\n",
      "average FP: 11.60 average FN: 24.40 \n",
      "Random under-sampling\n",
      "Train FP: 0 Train FN: 0; Test FP: 222 Test FN: 10\n",
      "Train FP: 0 Train FN: 0; Test FP: 184 Test FN: 6\n",
      "Train FP: 0 Train FN: 0; Test FP: 215 Test FN: 6\n",
      "Train FP: 0 Train FN: 0; Test FP: 179 Test FN: 14\n",
      "Train FP: 0 Train FN: 0; Test FP: 193 Test FN: 6\n",
      "average FP: 198.60 average FN: 8.40 \n",
      "Classifier: ada\n",
      "Random over-sampling\n",
      "Train FP: 261 Train FN: 98; Test FP: 77 Test FN: 14\n",
      "Train FP: 233 Train FN: 88; Test FP: 64 Test FN: 15\n",
      "Train FP: 281 Train FN: 145; Test FP: 70 Test FN: 15\n",
      "Train FP: 271 Train FN: 172; Test FP: 73 Test FN: 9\n",
      "Train FP: 304 Train FN: 125; Test FP: 83 Test FN: 10\n",
      "average FP: 73.40 average FN: 12.60 \n",
      "SMOTE over-sampling\n",
      "Train FP: 212 Train FN: 187; Test FP: 57 Test FN: 16\n",
      "Train FP: 191 Train FN: 192; Test FP: 57 Test FN: 18\n",
      "Train FP: 239 Train FN: 211; Test FP: 62 Test FN: 15\n",
      "Train FP: 193 Train FN: 211; Test FP: 59 Test FN: 14\n",
      "Train FP: 207 Train FN: 206; Test FP: 65 Test FN: 17\n",
      "average FP: 60.00 average FN: 16.00 \n",
      "ADASYN over-sampling\n",
      "Train FP: 188 Train FN: 213; Test FP: 61 Test FN: 16\n",
      "Train FP: 161 Train FN: 223; Test FP: 48 Test FN: 14\n",
      "Train FP: 227 Train FN: 195; Test FP: 60 Test FN: 13\n",
      "Train FP: 201 Train FN: 217; Test FP: 65 Test FN: 13\n",
      "Train FP: 219 Train FN: 208; Test FP: 69 Test FN: 15\n",
      "average FP: 60.60 average FN: 14.20 \n",
      "Random under-sampling\n",
      "Train FP: 1 Train FN: 0; Test FP: 203 Test FN: 11\n",
      "Train FP: 0 Train FN: 0; Test FP: 192 Test FN: 8\n",
      "Train FP: 1 Train FN: 0; Test FP: 206 Test FN: 7\n",
      "Train FP: 0 Train FN: 1; Test FP: 214 Test FN: 9\n",
      "Train FP: 0 Train FN: 2; Test FP: 217 Test FN: 4\n",
      "average FP: 206.40 average FN: 7.80 \n",
      "Classifier: ml\n",
      "Random over-sampling\n",
      "Train FP: 31 Train FN: 0; Test FP: 26 Test FN: 18\n",
      "Train FP: 32 Train FN: 0; Test FP: 27 Test FN: 24\n",
      "Train FP: 26 Train FN: 0; Test FP: 38 Test FN: 19\n",
      "Train FP: 39 Train FN: 0; Test FP: 28 Test FN: 20\n",
      "Train FP: 42 Train FN: 0; Test FP: 24 Test FN: 25\n",
      "average FP: 28.60 average FN: 21.20 \n",
      "SMOTE over-sampling\n",
      "Train FP: 27 Train FN: 0; Test FP: 28 Test FN: 22\n",
      "Train FP: 31 Train FN: 0; Test FP: 26 Test FN: 27\n",
      "Train FP: 41 Train FN: 1; Test FP: 31 Test FN: 21\n",
      "Train FP: 17 Train FN: 0; Test FP: 29 Test FN: 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train FP: 36 Train FN: 0; Test FP: 23 Test FN: 23\n",
      "average FP: 27.40 average FN: 23.40 \n",
      "ADASYN over-sampling\n",
      "Train FP: 24 Train FN: 0; Test FP: 24 Test FN: 20\n",
      "Train FP: 26 Train FN: 1; Test FP: 26 Test FN: 27\n",
      "Train FP: 39 Train FN: 0; Test FP: 34 Test FN: 18\n",
      "Train FP: 33 Train FN: 0; Test FP: 36 Test FN: 22\n",
      "Train FP: 48 Train FN: 0; Test FP: 22 Test FN: 25\n",
      "average FP: 28.40 average FN: 22.40 \n",
      "Random under-sampling\n",
      "Train FP: 24 Train FN: 23; Test FP: 299 Test FN: 10\n",
      "Train FP: 28 Train FN: 18; Test FP: 333 Test FN: 13\n",
      "Train FP: 23 Train FN: 26; Test FP: 309 Test FN: 11\n",
      "Train FP: 31 Train FN: 17; Test FP: 338 Test FN: 9\n",
      "Train FP: 21 Train FN: 16; Test FP: 330 Test FN: 9\n",
      "average FP: 321.80 average FN: 10.40 \n"
     ]
    }
   ],
   "source": [
    "clfs={\n",
    "    'gnb': GaussianNB(),\n",
    "    'svm': SVC(),\n",
    "    'lr':  LogisticRegression(),\n",
    "    'rfc': RandomForestClassifier(),\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'ada': AdaBoostClassifier(),\n",
    "    'ml': MLPClassifier()\n",
    "}\n",
    "cv = 5\n",
    "for clf_name in clfs:\n",
    "    print(\"Classifier: {0}\".format(clf_name))\n",
    "    # Logistic regression score with Random Over-sampling\n",
    "    print(\"Random over-sampling\")\n",
    "    FP, FN = imbalanced_cross_validation_score(clfs[clf_name], x, y, cv, FP_FN_score, RandomOverSampler())\n",
    "    print(\"average FP: %.2f average FN: %.2f \"%(FP, FN))\n",
    "\n",
    "    # Logistic regression score with SMOTE\n",
    "    print(\"SMOTE over-sampling\")\n",
    "    FP, FN = imbalanced_cross_validation_score(clfs[clf_name], x, y, cv, FP_FN_score, SMOTE())\n",
    "    print(\"average FP: %.2f average FN: %.2f \"%(FP, FN))\n",
    "\n",
    "    # Logistic regression score with ADASYN\n",
    "    print(\"ADASYN over-sampling\")\n",
    "    FP, FN = imbalanced_cross_validation_score(clfs[clf_name], x, y, cv, FP_FN_score, ADASYN())\n",
    "    print(\"average FP: %.2f average FN: %.2f \"%(FP, FN))\n",
    "\n",
    "    # Logistic regression score with Random Under Sampling\n",
    "    print(\"Random under-sampling\")\n",
    "    FP, FN = imbalanced_cross_validation_score(clfs[clf_name], x, y, cv, FP_FN_score, RandomUnderSampler())\n",
    "    print(\"average FP: %.2f average FN: %.2f \"%(FP, FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
