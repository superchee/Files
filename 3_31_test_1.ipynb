{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "# functions needed for pr_auc_score()\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# functions needed for imbalanced_cross_validation_score()\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# sampler objects\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, NeighbourhoodCleaningRule, AllKNN, InstanceHardnessThreshold\n",
    "\n",
    "# Classification models to compare\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.svm import SVC # SVM\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import preprocessing \n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc_score(clf, x, y):\n",
    "    '''\n",
    "        This function computes area under the precision-recall curve. \n",
    "    '''\n",
    "      \n",
    "    precisions, recalls,_ = precision_recall_curve(y, clf.predict_proba(x)[:,1], pos_label=1)\n",
    "    \n",
    "    return auc(recalls, precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Confusion_matrix(clf, x, y):\n",
    "    cm = metrics.confusion_matrix(y, clf.predict(x))\n",
    "    return (cm[0][0], cm[0][1], cm[1][0], cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalanced_cross_validation_score(clf, x, y, cv, scoring, sampler):\n",
    "    '''\n",
    "        This function computes the cross-validation score of a given \n",
    "        classifier using a choice of sampling function to mitigate \n",
    "        the class imbalance, and stratified k-fold sampling.\n",
    "        \n",
    "        The first five arguments are the same as \n",
    "        sklearn.model_selection.cross_val_score.\n",
    "        \n",
    "        - clf.predict_proba(x) returns class label probabilities\n",
    "        - clf.fit(x,y) trains the model\n",
    "        \n",
    "        - x = data\n",
    "        \n",
    "        - y = labels\n",
    "        \n",
    "        - cv = the number of folds in the cross validation\n",
    "        \n",
    "        - scoring(classifier, x, y) returns a float\n",
    "        \n",
    "        The last argument is a choice of random sampler: an object \n",
    "        similar to the sampler objects available from the python \n",
    "        package imbalanced-learn. In particular, this \n",
    "        object needs to have the method:\n",
    "        \n",
    "        sampler.fit_sample(x,y)\n",
    "        \n",
    "        See http://contrib.scikit-learn.org/imbalanced-learn/\n",
    "        for more details and examples of other sampling objects \n",
    "        available.  \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    cv_score = 0.\n",
    "    train_score = 0.\n",
    "    test_score = 0.\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    \n",
    "    # stratified k-fold creates folds with the same ratio of positive \n",
    "    # and negative samples as the entire dataset.\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=cv, random_state=0, shuffle=False)\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(x,y):\n",
    "        \n",
    "        xfold_train_sampled, yfold_train_sampled = sampler.fit_sample(x[train_idx],y[train_idx])\n",
    "        clf.fit(xfold_train_sampled, yfold_train_sampled)\n",
    "        \n",
    "        TP_train, FP_train, FN_train, TN_train = scoring(clf, xfold_train_sampled, yfold_train_sampled)\n",
    "        TP_test, FP_test, FN_test, TN_test  = scoring(clf, x[test_idx], y[test_idx])\n",
    "        \n",
    "        print(\"Train FP: {0} Train FN: {1}; Test FP: {2} Test FN: {3}\".format(FP_train, FN_train, FP_test, FN_test))\n",
    "        \n",
    "        TP += TP_test\n",
    "        FP += FP_test\n",
    "        FN += FN_test\n",
    "        TN += TN_test\n",
    "        \n",
    "\n",
    "    ave_tp = TP/cv\n",
    "    ave_fp = FP/cv\n",
    "    ave_fn = FN/cv\n",
    "    ave_tn = TN/cv\n",
    "    \n",
    "    \n",
    "    sensitivity = ave_tp/(ave_tp + ave_fn)\n",
    "    specificity = ave_tn/(ave_fp + ave_tn)\n",
    "    \n",
    "    g_mean = math.sqrt(sensitivity * specificity)\n",
    "    mcc = (ave_tp * ave_tn - ave_fp * ave_fn)/math.sqrt((ave_tp + ave_fp) * (ave_tp + ave_fn) * (ave_tn + ave_fp) * (ave_tn + ave_fn))\n",
    "    \n",
    "    values = [sensitivity, specificity, g_mean, mcc]\n",
    "    \n",
    "        \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_o = pd.read_csv('financial_data.csv')\n",
    "y_train_o = pd.read_csv('revealed_businesses.csv')\n",
    "\n",
    "x_test_o = pd.read_csv(\"testing_data.csv\")\n",
    "\n",
    "x_train_o.replace('?', np.nan, inplace=True)\n",
    "x_train_o = x_train_o.astype('float64')\n",
    "\n",
    "\n",
    "x_test_o.replace('?', np.nan, inplace=True)\n",
    "x_test_o = x_test_o.astype('float64')\n",
    "\n",
    "data_all = x_train_o.merge(y_train_o, on='Var1', how = 'left')\n",
    "\n",
    "data_nolabel = data_all[data_all.Var66.isnull()]\n",
    "data_label = data_all[data_all.Var66.notnull()]\n",
    "\n",
    "data_nolabel_v = data_nolabel.drop(columns=['Var1', 'Var66'])\n",
    "data_nolabel_id = data_nolabel['Var1']\n",
    "\n",
    "data_label_v = data_label.drop(columns=['Var1', 'Var66'])\n",
    "data_label_id = data_label['Var1']\n",
    "\n",
    "x_test_v = x_test_o.drop(columns=['Var1'])\n",
    "\n",
    "# data_all_v = data_all.drop(columns=['Var1', 'Var66'])\n",
    "# data_all_v_mean = data_all_v.mean()\n",
    "# data_all_v_f = data_all_v.fillna(data_all_v_mean)\n",
    "# minmax_scaler = preprocessing.MinMaxScaler().fit(data_all_v)\n",
    "\n",
    "# data_nolabel_v_f = data_nolabel_v.fillna(data_all_v_mean)\n",
    "# data_label_v_f = data_label_v.fillna(data_all_v_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_selected = ['Var28', 'Var22', 'Var25', 'Var7', 'Var27', 'Var17', 'Var35', 'Var30',\n",
    "#        'Var6', 'Var63']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = pd.concat([data_label_v, x_test_v], axis=0)\n",
    "\n",
    "# x_all_s = x_all[feature_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_f = x_all.fillna(x_all.mean()).values\n",
    "#x_all_f_scale = preprocessing.MinMaxScaler().fit_transform(x_all_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_all_f[:4879,:]\n",
    "y = data_label['Var66'].values\n",
    "\n",
    "x_test_scale = x_all_f[4879:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = RandomOverSampler(random_state=94).fit_sample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(learning_rate=0.05,scale_pos_weight=0.5, max_depth=6, subsample=0.8, n_estimators=500, gamma=0, colsample_bytree=1)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred_dt = clf.predict(x_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1418\n",
       "1.0      82\n",
       "Name: Is_Bankrupted, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_business_id = x_test_o['Var1']\n",
    "df_y = pd.DataFrame(y_pred_dt, columns=[\"Is_Bankrupted\"])\n",
    "upload = pd.concat([x_test_business_id, df_y], axis=1)\n",
    "df_y[\"Is_Bankrupted\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = upload.astype('int32')\n",
    "upload.columns=['Business_ID', 'Is_Bankrupted']\n",
    "upload.to_csv('3_31_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
