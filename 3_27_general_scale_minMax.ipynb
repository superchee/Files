{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# functions needed for pr_auc_score()\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# functions needed for imbalanced_cross_validation_score()\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# sampler objects\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Classification models to compare\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.svm import SVC # SVM\n",
    "\n",
    "from sklearn import preprocessing \n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc_score(clf, x, y):\n",
    "    '''\n",
    "        This function computes area under the precision-recall curve. \n",
    "    '''\n",
    "      \n",
    "    precisions, recalls,_ = precision_recall_curve(y, clf.predict_proba(x)[:,1], pos_label=1)\n",
    "    \n",
    "    return auc(recalls, precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FP_FN_score(clf, x, y):\n",
    "    cm = metrics.confusion_matrix(y, clf.predict(x))\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "    return FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalanced_cross_validation_score(clf, x, y, cv, scoring, sampler):\n",
    "    '''\n",
    "        This function computes the cross-validation score of a given \n",
    "        classifier using a choice of sampling function to mitigate \n",
    "        the class imbalance, and stratified k-fold sampling.\n",
    "        \n",
    "        The first five arguments are the same as \n",
    "        sklearn.model_selection.cross_val_score.\n",
    "        \n",
    "        - clf.predict_proba(x) returns class label probabilities\n",
    "        - clf.fit(x,y) trains the model\n",
    "        \n",
    "        - x = data\n",
    "        \n",
    "        - y = labels\n",
    "        \n",
    "        - cv = the number of folds in the cross validation\n",
    "        \n",
    "        - scoring(classifier, x, y) returns a float\n",
    "        \n",
    "        The last argument is a choice of random sampler: an object \n",
    "        similar to the sampler objects available from the python \n",
    "        package imbalanced-learn. In particular, this \n",
    "        object needs to have the method:\n",
    "        \n",
    "        sampler.fit_sample(x,y)\n",
    "        \n",
    "        See http://contrib.scikit-learn.org/imbalanced-learn/\n",
    "        for more details and examples of other sampling objects \n",
    "        available.  \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    cv_score = 0.\n",
    "    train_score = 0.\n",
    "    test_score = 0.\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    # stratified k-fold creates folds with the same ratio of positive \n",
    "    # and negative samples as the entire dataset.\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=cv, random_state=0, shuffle=False)\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(x,y):\n",
    "        \n",
    "        xfold_train_sampled, yfold_train_sampled = sampler.fit_sample(x[train_idx],y[train_idx])\n",
    "        clf.fit(xfold_train_sampled, yfold_train_sampled)\n",
    "        \n",
    "        FP_train, FN_train = scoring(clf, xfold_train_sampled, yfold_train_sampled)\n",
    "        FP_test, FN_test  = scoring(clf, x[test_idx], y[test_idx])\n",
    "        \n",
    "        print(\"Train FP: {0} Train FN: {1}; Test FP: {2} Test FN: {3}\".format(FP_train,FN_train, FP_test, FN_test))\n",
    "\n",
    "        FP += FP_test\n",
    "        FN += FN_test\n",
    "        \n",
    "    return FP/cv, FN/cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_o = pd.read_csv('financial_data.csv')\n",
    "y_train_o = pd.read_csv('revealed_businesses.csv')\n",
    "\n",
    "x_test_o = pd.read_csv(\"testing_data.csv\")\n",
    "\n",
    "x_train_o.replace('?', np.nan, inplace=True)\n",
    "x_train_o = x_train_o.astype('float64')\n",
    "\n",
    "\n",
    "x_test_o.replace('?', np.nan, inplace=True)\n",
    "x_test_o = x_test_o.astype('float64')\n",
    "\n",
    "data_all = x_train_o.merge(y_train_o, on='Var1', how = 'left')\n",
    "\n",
    "data_nolabel = data_all[data_all.Var66.isnull()]\n",
    "data_label = data_all[data_all.Var66.notnull()]\n",
    "\n",
    "data_nolabel_v = data_nolabel.drop(columns=['Var1', 'Var66'])\n",
    "data_nolabel_id = data_nolabel['Var1']\n",
    "\n",
    "data_label_v = data_label.drop(columns=['Var1', 'Var66'])\n",
    "data_label_id = data_label['Var1']\n",
    "\n",
    "data_nolabel_v_f = data_nolabel_v.fillna(data_nolabel_v.mean())\n",
    "data_label_v_f = data_label_v.fillna(data_label_v.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_label_v_f.values\n",
    "y = data_label['Var66'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocessing.MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: gnb\n",
      "Random over-sampling\n",
      "Train FP: 3457 Train FN: 63; Test FP: 862 Test FN: 2\n",
      "Train FP: 3366 Train FN: 77; Test FP: 846 Test FN: 4\n",
      "Train FP: 3366 Train FN: 81; Test FP: 865 Test FN: 4\n",
      "Train FP: 3332 Train FN: 86; Test FP: 831 Test FN: 3\n",
      "Train FP: 3443 Train FN: 45; Test FP: 865 Test FN: 4\n",
      "average FP: 853.80 average FN: 3.40 \n",
      "SMOTE over-sampling\n",
      "Train FP: 3350 Train FN: 85; Test FP: 830 Test FN: 2\n",
      "Train FP: 3259 Train FN: 102; Test FP: 826 Test FN: 5\n",
      "Train FP: 3248 Train FN: 121; Test FP: 841 Test FN: 6\n",
      "Train FP: 3249 Train FN: 99; Test FP: 802 Test FN: 4\n",
      "Train FP: 3318 Train FN: 68; Test FP: 824 Test FN: 5\n",
      "average FP: 824.60 average FN: 4.40 \n",
      "ADASYN over-sampling\n",
      "Train FP: 3322 Train FN: 93; Test FP: 822 Test FN: 2\n",
      "Train FP: 3269 Train FN: 92; Test FP: 827 Test FN: 5\n",
      "Train FP: 3234 Train FN: 133; Test FP: 829 Test FN: 6\n",
      "Train FP: 3252 Train FN: 97; Test FP: 803 Test FN: 4\n",
      "Train FP: 3322 Train FN: 79; Test FP: 829 Test FN: 5\n",
      "average FP: 822.00 average FN: 4.40 \n",
      "Random under-sampling\n",
      "Train FP: 12 Train FN: 96; Test FP: 118 Test FN: 27\n",
      "Train FP: 114 Train FN: 5; Test FP: 807 Test FN: 5\n",
      "Train FP: 9 Train FN: 106; Test FP: 92 Test FN: 28\n",
      "Train FP: 15 Train FN: 92; Test FP: 134 Test FN: 22\n",
      "Train FP: 9 Train FN: 113; Test FP: 96 Test FN: 30\n",
      "average FP: 249.40 average FN: 22.40 \n",
      "Classifier: svm\n",
      "Random over-sampling\n",
      "Train FP: 1235 Train FN: 1308; Test FP: 327 Test FN: 14\n",
      "Train FP: 1924 Train FN: 770; Test FP: 477 Test FN: 5\n",
      "Train FP: 446 Train FN: 2546; Test FP: 117 Test FN: 26\n",
      "Train FP: 1214 Train FN: 1621; Test FP: 310 Test FN: 20\n",
      "Train FP: 586 Train FN: 2244; Test FP: 140 Test FN: 27\n",
      "average FP: 274.20 average FN: 18.40 \n",
      "SMOTE over-sampling\n",
      "Train FP: 2968 Train FN: 166; Test FP: 750 Test FN: 5\n",
      "Train FP: 3650 Train FN: 51; Test FP: 911 Test FN: 0\n",
      "Train FP: 2776 Train FN: 252; Test FP: 700 Test FN: 6\n",
      "Train FP: 2674 Train FN: 518; Test FP: 682 Test FN: 5\n",
      "Train FP: 3045 Train FN: 214; Test FP: 766 Test FN: 2\n",
      "average FP: 761.80 average FN: 3.60 \n",
      "ADASYN over-sampling\n",
      "Train FP: 3742 Train FN: 13; Test FP: 932 Test FN: 0\n",
      "Train FP: 33 Train FN: 3736; Test FP: 5 Test FN: 33\n",
      "Train FP: 31 Train FN: 3715; Test FP: 6 Test FN: 34\n",
      "Train FP: 2816 Train FN: 512; Test FP: 727 Test FN: 5\n",
      "Train FP: 27 Train FN: 3735; Test FP: 9 Test FN: 33\n",
      "average FP: 335.80 average FN: 21.00 \n",
      "Random under-sampling\n",
      "Train FP: 36 Train FN: 65; Test FP: 240 Test FN: 21\n",
      "Train FP: 135 Train FN: 0; Test FP: 942 Test FN: 0\n",
      "Train FP: 11 Train FN: 109; Test FP: 107 Test FN: 27\n",
      "Train FP: 27 Train FN: 86; Test FP: 252 Test FN: 27\n",
      "Train FP: 9 Train FN: 108; Test FP: 144 Test FN: 27\n",
      "average FP: 337.00 average FN: 20.40 \n",
      "Classifier: lr\n",
      "Random over-sampling\n",
      "Train FP: 1067 Train FN: 1382; Test FP: 273 Test FN: 15\n",
      "Train FP: 1011 Train FN: 1457; Test FP: 269 Test FN: 13\n",
      "Train FP: 1051 Train FN: 1379; Test FP: 241 Test FN: 14\n",
      "Train FP: 1100 Train FN: 1351; Test FP: 288 Test FN: 15\n",
      "Train FP: 1086 Train FN: 1359; Test FP: 249 Test FN: 13\n",
      "average FP: 264.00 average FN: 14.00 \n",
      "SMOTE over-sampling\n",
      "Train FP: 1168 Train FN: 1240; Test FP: 294 Test FN: 14\n",
      "Train FP: 1146 Train FN: 1266; Test FP: 307 Test FN: 11\n",
      "Train FP: 1182 Train FN: 1273; Test FP: 283 Test FN: 13\n",
      "Train FP: 1196 Train FN: 1216; Test FP: 322 Test FN: 12\n",
      "Train FP: 1167 Train FN: 1233; Test FP: 266 Test FN: 12\n",
      "average FP: 294.40 average FN: 12.40 \n",
      "ADASYN over-sampling\n",
      "Train FP: 1201 Train FN: 1182; Test FP: 300 Test FN: 14\n",
      "Train FP: 1136 Train FN: 1257; Test FP: 308 Test FN: 9\n",
      "Train FP: 1129 Train FN: 1308; Test FP: 258 Test FN: 13\n",
      "Train FP: 1170 Train FN: 1257; Test FP: 306 Test FN: 14\n",
      "Train FP: 1144 Train FN: 1288; Test FP: 262 Test FN: 13\n",
      "average FP: 286.80 average FN: 12.60 \n",
      "Random under-sampling\n",
      "Train FP: 35 Train FN: 63; Test FP: 306 Test FN: 15\n",
      "Train FP: 32 Train FN: 63; Test FP: 246 Test FN: 9\n",
      "Train FP: 36 Train FN: 45; Test FP: 305 Test FN: 15\n",
      "Train FP: 36 Train FN: 56; Test FP: 291 Test FN: 16\n",
      "Train FP: 29 Train FN: 63; Test FP: 191 Test FN: 18\n",
      "average FP: 267.80 average FN: 14.60 \n",
      "Classifier: rfc\n",
      "Random over-sampling\n",
      "Train FP: 0 Train FN: 0; Test FP: 4 Test FN: 26\n",
      "Train FP: 0 Train FN: 0; Test FP: 2 Test FN: 28\n",
      "Train FP: 0 Train FN: 0; Test FP: 2 Test FN: 21\n",
      "Train FP: 0 Train FN: 0; Test FP: 0 Test FN: 25\n",
      "Train FP: 0 Train FN: 0; Test FP: 2 Test FN: 30\n",
      "average FP: 2.00 average FN: 26.00 \n",
      "SMOTE over-sampling\n",
      "Train FP: 1 Train FN: 4; Test FP: 13 Test FN: 19\n",
      "Train FP: 1 Train FN: 4; Test FP: 17 Test FN: 22\n",
      "Train FP: 0 Train FN: 2; Test FP: 9 Test FN: 19\n",
      "Train FP: 1 Train FN: 1; Test FP: 6 Test FN: 21\n",
      "Train FP: 0 Train FN: 2; Test FP: 11 Test FN: 23\n",
      "average FP: 11.20 average FN: 20.80 \n",
      "ADASYN over-sampling\n",
      "Train FP: 2 Train FN: 0; Test FP: 18 Test FN: 22\n",
      "Train FP: 1 Train FN: 2; Test FP: 26 Test FN: 22\n",
      "Train FP: 0 Train FN: 0; Test FP: 10 Test FN: 20\n",
      "Train FP: 2 Train FN: 2; Test FP: 9 Test FN: 20\n",
      "Train FP: 0 Train FN: 1; Test FP: 7 Test FN: 23\n",
      "average FP: 14.00 average FN: 21.40 \n",
      "Random under-sampling\n",
      "Train FP: 0 Train FN: 1; Test FP: 211 Test FN: 9\n",
      "Train FP: 3 Train FN: 1; Test FP: 284 Test FN: 13\n",
      "Train FP: 0 Train FN: 2; Test FP: 239 Test FN: 16\n",
      "Train FP: 0 Train FN: 4; Test FP: 209 Test FN: 11\n",
      "Train FP: 0 Train FN: 3; Test FP: 205 Test FN: 11\n",
      "average FP: 229.60 average FN: 12.00 \n",
      "Classifier: et\n",
      "Random over-sampling\n",
      "Train FP: 0 Train FN: 0; Test FP: 2 Test FN: 33\n",
      "Train FP: 0 Train FN: 0; Test FP: 3 Test FN: 29\n",
      "Train FP: 0 Train FN: 0; Test FP: 3 Test FN: 31\n",
      "Train FP: 0 Train FN: 0; Test FP: 0 Test FN: 31\n",
      "Train FP: 0 Train FN: 0; Test FP: 0 Test FN: 31\n",
      "average FP: 1.60 average FN: 31.00 \n",
      "SMOTE over-sampling\n",
      "Train FP: 0 Train FN: 0; Test FP: 16 Test FN: 27\n",
      "Train FP: 0 Train FN: 0; Test FP: 10 Test FN: 27\n",
      "Train FP: 0 Train FN: 0; Test FP: 8 Test FN: 20\n",
      "Train FP: 0 Train FN: 0; Test FP: 9 Test FN: 25\n",
      "Train FP: 0 Train FN: 0; Test FP: 6 Test FN: 26\n",
      "average FP: 9.80 average FN: 25.00 \n",
      "ADASYN over-sampling\n",
      "Train FP: 0 Train FN: 0; Test FP: 13 Test FN: 27\n",
      "Train FP: 0 Train FN: 0; Test FP: 14 Test FN: 26\n",
      "Train FP: 0 Train FN: 0; Test FP: 9 Test FN: 21\n",
      "Train FP: 0 Train FN: 0; Test FP: 14 Test FN: 25\n",
      "Train FP: 0 Train FN: 0; Test FP: 12 Test FN: 26\n",
      "average FP: 12.40 average FN: 25.00 \n",
      "Random under-sampling\n",
      "Train FP: 0 Train FN: 0; Test FP: 171 Test FN: 12\n",
      "Train FP: 0 Train FN: 0; Test FP: 252 Test FN: 12\n",
      "Train FP: 0 Train FN: 0; Test FP: 217 Test FN: 9\n",
      "Train FP: 0 Train FN: 0; Test FP: 198 Test FN: 9\n",
      "Train FP: 0 Train FN: 0; Test FP: 192 Test FN: 7\n",
      "average FP: 206.00 average FN: 9.80 \n",
      "Classifier: ada\n",
      "Random over-sampling\n",
      "Train FP: 281 Train FN: 193; Test FP: 83 Test FN: 13\n",
      "Train FP: 264 Train FN: 126; Test FP: 74 Test FN: 13\n",
      "Train FP: 314 Train FN: 143; Test FP: 78 Test FN: 16\n",
      "Train FP: 268 Train FN: 106; Test FP: 70 Test FN: 10\n",
      "Train FP: 312 Train FN: 180; Test FP: 83 Test FN: 9\n",
      "average FP: 77.60 average FN: 12.20 \n",
      "SMOTE over-sampling\n",
      "Train FP: 210 Train FN: 217; Test FP: 59 Test FN: 17\n",
      "Train FP: 208 Train FN: 208; Test FP: 62 Test FN: 18\n",
      "Train FP: 251 Train FN: 228; Test FP: 52 Test FN: 18\n",
      "Train FP: 214 Train FN: 250; Test FP: 65 Test FN: 15\n",
      "Train FP: 215 Train FN: 248; Test FP: 63 Test FN: 14\n",
      "average FP: 60.20 average FN: 16.40 \n",
      "ADASYN over-sampling\n",
      "Train FP: 225 Train FN: 224; Test FP: 66 Test FN: 15\n",
      "Train FP: 207 Train FN: 218; Test FP: 69 Test FN: 17\n",
      "Train FP: 234 Train FN: 251; Test FP: 55 Test FN: 17\n",
      "Train FP: 206 Train FN: 256; Test FP: 58 Test FN: 12\n",
      "Train FP: 231 Train FN: 228; Test FP: 66 Test FN: 15\n",
      "average FP: 62.80 average FN: 15.20 \n",
      "Random under-sampling\n",
      "Train FP: 1 Train FN: 1; Test FP: 243 Test FN: 7\n",
      "Train FP: 0 Train FN: 0; Test FP: 219 Test FN: 5\n",
      "Train FP: 2 Train FN: 4; Test FP: 188 Test FN: 9\n",
      "Train FP: 1 Train FN: 1; Test FP: 210 Test FN: 5\n",
      "Train FP: 3 Train FN: 2; Test FP: 175 Test FN: 7\n",
      "average FP: 207.00 average FN: 6.60 \n",
      "Classifier: ml\n",
      "Random over-sampling\n",
      "Train FP: 1569 Train FN: 549; Test FP: 391 Test FN: 11\n",
      "Train FP: 1812 Train FN: 368; Test FP: 462 Test FN: 7\n",
      "Train FP: 1186 Train FN: 917; Test FP: 286 Test FN: 14\n",
      "Train FP: 1405 Train FN: 608; Test FP: 373 Test FN: 6\n",
      "Train FP: 1390 Train FN: 665; Test FP: 340 Test FN: 8\n",
      "average FP: 370.40 average FN: 9.20 \n",
      "SMOTE over-sampling\n",
      "Train FP: 1657 Train FN: 313; Test FP: 428 Test FN: 11\n",
      "Train FP: 903 Train FN: 1106; Test FP: 245 Test FN: 18\n",
      "Train FP: 1625 Train FN: 565; Test FP: 398 Test FN: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train FP: 1318 Train FN: 801; Test FP: 364 Test FN: 7\n",
      "Train FP: 1170 Train FN: 895; Test FP: 280 Test FN: 13\n",
      "average FP: 343.00 average FN: 11.60 \n",
      "ADASYN over-sampling\n",
      "Train FP: 1305 Train FN: 666; Test FP: 323 Test FN: 13\n",
      "Train FP: 972 Train FN: 830; Test FP: 272 Test FN: 16\n",
      "Train FP: 1157 Train FN: 875; Test FP: 284 Test FN: 14\n",
      "Train FP: 1118 Train FN: 887; Test FP: 299 Test FN: 11\n",
      "Train FP: 1038 Train FN: 973; Test FP: 246 Test FN: 14\n",
      "average FP: 284.80 average FN: 13.60 \n",
      "Random under-sampling\n",
      "Train FP: 61 Train FN: 41; Test FP: 407 Test FN: 12\n",
      "Train FP: 48 Train FN: 45; Test FP: 328 Test FN: 8\n",
      "Train FP: 37 Train FN: 47; Test FP: 293 Test FN: 13\n",
      "Train FP: 46 Train FN: 55; Test FP: 305 Test FN: 17\n",
      "Train FP: 25 Train FN: 58; Test FP: 282 Test FN: 18\n",
      "average FP: 323.00 average FN: 13.60 \n"
     ]
    }
   ],
   "source": [
    "clfs={\n",
    "    'gnb': GaussianNB(),\n",
    "    'svm': SVC(),\n",
    "    'lr':  LogisticRegression(),\n",
    "    'rfc': RandomForestClassifier(),\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'ada': AdaBoostClassifier(),\n",
    "    'ml': MLPClassifier()\n",
    "}\n",
    "cv = 5\n",
    "for clf_name in clfs:\n",
    "    print(\"Classifier: {0}\".format(clf_name))\n",
    "    # Logistic regression score with Random Over-sampling\n",
    "    print(\"Random over-sampling\")\n",
    "    FP, FN = imbalanced_cross_validation_score(clfs[clf_name], x, y, cv, FP_FN_score, RandomOverSampler())\n",
    "    print(\"average FP: %.2f average FN: %.2f \"%(FP, FN))\n",
    "\n",
    "    # Logistic regression score with SMOTE\n",
    "    print(\"SMOTE over-sampling\")\n",
    "    FP, FN = imbalanced_cross_validation_score(clfs[clf_name], x, y, cv, FP_FN_score, SMOTE())\n",
    "    print(\"average FP: %.2f average FN: %.2f \"%(FP, FN))\n",
    "\n",
    "    # Logistic regression score with ADASYN\n",
    "    print(\"ADASYN over-sampling\")\n",
    "    FP, FN = imbalanced_cross_validation_score(clfs[clf_name], x, y, cv, FP_FN_score, ADASYN())\n",
    "    print(\"average FP: %.2f average FN: %.2f \"%(FP, FN))\n",
    "\n",
    "    # Logistic regression score with Random Under Sampling\n",
    "    print(\"Random under-sampling\")\n",
    "    FP, FN = imbalanced_cross_validation_score(clfs[clf_name], x, y, cv, FP_FN_score, RandomUnderSampler())\n",
    "    print(\"average FP: %.2f average FN: %.2f \"%(FP, FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
